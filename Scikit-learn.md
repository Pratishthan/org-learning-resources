# ğŸ§­ Scikit-learn Complete Learning Roadmap

A structured roadmap to master **scikit-learn (sklearn)** â€” from beginner to expert â€” including topics, resources, and practice projects.

---

## ğŸ“… PHASE 1: Foundation Setup (1 week)

### ğŸ¯ Goal
Understand what scikit-learn is and how its workflow fits into ML.

### ğŸ§© Topics
- Scikit-learn architecture & API design
- Loading datasets (`iris`, `digits`, `wine`, etc.)
- `train_test_split`, `cross_val_score`
- Fit â†’ Transform â†’ Predict pattern
- Basics of NumPy, Pandas, and Matplotlib

### ğŸ“˜ Resources
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Corey Schafer â€“ Machine Learning with Scikit-learn (YouTube)](https://www.youtube.com/watch?v=7eh4d6sabA0)
- [FreeCodeCamp â€“ Machine Learning with Python (5 hrs)](https://www.youtube.com/watch?v=7eh4d6sabA0)
- *Introduction to Machine Learning with Python* â€” Andreas MÃ¼ller & Sarah Guido

### ğŸ§  Practice
- Load and visualize the Iris dataset
- Train/test a simple `LogisticRegression` model

---

## âš™ï¸ PHASE 2: Data Preprocessing & Pipelines (2 weeks)

### ğŸ¯ Goal
Learn to clean, encode, scale, and prepare data efficiently.

### ğŸ§© Topics
- **Preprocessing**
  - `StandardScaler`, `MinMaxScaler`, `SimpleImputer`, `OneHotEncoder`, `LabelEncoder`
  - `PolynomialFeatures`, `Binarizer`
- **Feature Selection**
  - `SelectKBest`, `RFE`, `VarianceThreshold`
- **Pipelines**
  - `Pipeline`, `make_pipeline`, `ColumnTransformer`
  - Custom Transformers (`FunctionTransformer`)

### ğŸ“˜ Resources
- [Preprocessing & Feature Engineering Guide](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Pipelines & Composite Estimators](https://scikit-learn.org/stable/modules/compose.html)
- [Data School â€“ Pipelines in Scikit-learn (YouTube)](https://www.youtube.com/watch?v=84gqSbLcBFE)
- *Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow* (Ch. 2â€“3)

### ğŸ§  Practice
- Build a pipeline combining preprocessing + model  
- Compare performance before and after scaling

---

## ğŸ§® PHASE 3: Supervised Learning (3â€“4 weeks)

### ğŸ¯ Goal
Learn regression & classification algorithms and their evaluation.

### ğŸ§© Regression Models
- `LinearRegression`, `Ridge`, `Lasso`, `ElasticNet`
- `SVR`, `DecisionTreeRegressor`, `RandomForestRegressor`
- `KNeighborsRegressor`, `GradientBoostingRegressor`

### ğŸ§© Classification Models
- `LogisticRegression`, `KNeighborsClassifier`
- `DecisionTreeClassifier`, `RandomForestClassifier`
- `SVC`, `GaussianNB`, `MultinomialNB`
- `AdaBoostClassifier`, `GradientBoostingClassifier`

### ğŸ§© Evaluation Metrics
- `classification_report`, `confusion_matrix`, `accuracy_score`
- `roc_auc_score`, `precision_recall_curve`
- `mean_squared_error`, `r2_score`
- Cross-validation: `cross_val_score`, `KFold`

### ğŸ“˜ Resources
- [Supervised Learning Overview](https://scikit-learn.org/stable/supervised_learning.html)
- [StatQuest â€“ Logistic Regression, Decision Trees, Random Forests (YouTube)](https://www.youtube.com/user/joshstarmer)
- [Krish Naik â€“ Scikit-learn Regression & Classification Playlist](https://www.youtube.com/@krishnaik06)
- *Python Machine Learning* by Sebastian Raschka (Ch. 3â€“6)

### ğŸ§  Practice
- Compare models on the same dataset  
- Tune hyperparameters with `GridSearchCV` and `RandomizedSearchCV`  
- Plot confusion matrix & ROC curve

---

## ğŸ” PHASE 4: Unsupervised Learning (2â€“3 weeks)

### ğŸ¯ Goal
Understand clustering, dimensionality reduction, and unsupervised metrics.

### ğŸ§© Topics
- **Clustering**: `KMeans`, `DBSCAN`, `AgglomerativeClustering`, `MeanShift`
- **Dimensionality Reduction**: `PCA`, `KernelPCA`, `NMF`
- **Manifold Learning**: `t-SNE`, `Isomap`
- **Metrics**: Silhouette Score, Daviesâ€“Bouldin Index

### ğŸ“˜ Resources
- [Clustering Guide](https://scikit-learn.org/stable/modules/clustering.html)
- [PCA and Decomposition](https://scikit-learn.org/stable/modules/decomposition.html)
- [StatQuest â€“ PCA and Clustering Explained (YouTube)](https://www.youtube.com/watch?v=FgakZw6K1QQ)
- [Kaggle â€“ Unsupervised Learning Course](https://www.kaggle.com/learn/unsupervised-learning)

### ğŸ§  Practice
- Cluster customers by spending behavior (`KMeans`)  
- Visualize high-dimensional data with PCA + t-SNE

---

## ğŸ§  PHASE 5: Model Selection, Validation & Optimization (2 weeks)

### ğŸ¯ Goal
Master hyperparameter tuning and ensemble techniques.

### ğŸ§© Topics
- `GridSearchCV`, `RandomizedSearchCV`
- Custom scorers with `make_scorer`
- Handling imbalance: `SMOTE`, `class_weight`
- Ensemble Learning:
  - `BaggingClassifier`, `VotingClassifier`, `StackingClassifier`
- Model persistence with `joblib.dump()` / `joblib.load()`

### ğŸ“˜ Resources
- [Model Evaluation & Tuning Guide](https://scikit-learn.org/stable/model_evaluation.html)
- [Data School â€“ GridSearchCV Tutorial (YouTube)](https://www.youtube.com/watch?v=Gol_qOgRqfA)
- *Hands-On Machine Learning* (Ch. 7â€“8)

### ğŸ§  Practice
- Tune RandomForest hyperparameters  
- Build stacking ensemble of 3 classifiers  
- Save & reload models with Joblib

---

## âš¡ PHASE 6: Advanced Topics & Customization (3â€“4 weeks)

### ğŸ¯ Goal
Learn to extend and customize scikit-learn for production-level use.

### ğŸ§© Topics
- Custom Estimators (`BaseEstimator`, `TransformerMixin`)
- Pipeline debugging and visualization (`set_output`, `get_feature_names_out`)
- Feature Importance:
  - `PermutationImportance`, `SHAP`, `LIME`
- Model interpretability and explainability
- Integration with XGBoost, LightGBM, TensorFlow

### ğŸ“˜ Resources
- [Developing Custom Estimators](https://scikit-learn.org/stable/developers/develop.html)
- [Custom Transformers in Scikit-learn (TDS Blog)](https://towardsdatascience.com/custom-transformers-in-scikit-learn-3f7838b4f8b7)
- [SHAP & LIME Explained â€“ StatQuest / Krish Naik (YouTube)](https://www.youtube.com/watch?v=0oz9nsL0K7Y)
- *Interpretable Machine Learning* by Christoph Molnar (Free)

### ğŸ§  Practice
- Build a custom outlier-removal transformer  
- Use SHAP to interpret model predictions  
- Combine Scikit-learn with XGBoost

---

## ğŸš€ PHASE 7: Projects & Practice (Ongoing)

### ğŸ¯ Goal
Apply all concepts end-to-end in real-world projects.

### ğŸ§© Project Ideas
1. ğŸ  **House Price Prediction** â€” Regression + Feature Engineering  
2. ğŸ“§ **Spam Classifier** â€” NLP + Naive Bayes + Pipelines  
3. ğŸ›’ **Customer Segmentation** â€” KMeans + PCA  
4. ğŸ’³ **Credit Card Fraud Detection** â€” Imbalanced data + ROC analysis  
5. ğŸŒ **Web App (Flask/Streamlit)** â€” Deploy Scikit-learn model

### ğŸ“˜ Resources
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [Scikit-learn Tutorials by DataCamp](https://www.datacamp.com/tutorial/scikit-learn-tutorial-machine-learning)
- [FreeCodeCamp â€“ End-to-End ML Project](https://www.youtube.com/watch?v=7eh4d6sabA0)

---

## ğŸ Final Outcome

By completing this roadmap, you will:
âœ… Understand every major Scikit-learn module  
âœ… Build and deploy end-to-end ML pipelines  
âœ… Have multiple hands-on ML projects for your portfolio

---

**Author:** *Vinayak Sharma*  
**Version:** 1.0  
